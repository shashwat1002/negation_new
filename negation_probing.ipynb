{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrcreator/research/main_thread/initial_experiments/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer, RobertaConfig\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader\n",
    "import datasets\n",
    "from icecream import ic\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaWrapper(Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Wrapper on roberta that gives mean-pooled representations of each layer in a list\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.model_obj = RobertaModel.from_pretrained(\n",
    "            \"roberta-base\").eval()\n",
    "        self.model_obj.eval()\n",
    "        self.tokenizer_obj = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "        self.config_obj = RobertaConfig.from_pretrained(\"roberta-base\")\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, input_text):\n",
    "\n",
    "        encoder_ret = self.tokenizer_obj(\n",
    "            input_text, truncation=True, return_tensors=\"pt\", padding=True).to(self.device)\n",
    "\n",
    "        encoder_text_ids = encoder_ret.input_ids.to(self.device)\n",
    "        attention_mask = encoder_ret.attention_mask.to(self.device) # 1 for not pad\n",
    "\n",
    "        ic(encoder_text_ids.device)\n",
    "        ic(self.model_obj.device)\n",
    "        encoder_states = self.model_obj(\n",
    "            encoder_text_ids, output_hidden_states=True, attention_mask=attention_mask)\n",
    "\n",
    "        hs_tuple = encoder_states[\"hidden_states\"]\n",
    "\n",
    "        mean_pooled_all_layers = []\n",
    "\n",
    "        for layer, hs in enumerate(hs_tuple):\n",
    "            ic(hs_tuple[layer].size())\n",
    "            # hs = hs_tuple[layer] # (batch_size x sequence_length x dimension)\n",
    "            hs_masked = hs * attention_mask[:, :, None] # ideally zeros out the pad associated representations\n",
    "            ic(hs_masked.size())\n",
    "            seq_lengths = attention_mask.sum(dim=1) # each line here represents sequence length\n",
    "\n",
    "            hs_masked_sum = hs_masked.sum(dim=1)\n",
    "            hs_avg = hs_masked_sum / seq_lengths[:, None]\n",
    "            mean_pooled_all_layers.append(hs_avg)\n",
    "\n",
    "        return mean_pooled_all_layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Found cached dataset data_xor (/home/mrcreator/research/main_thread/fresh_repo/{'cache_dir': None, 'config_name': None, 'data_dir': None, 'data_files': None, 'hash': '70230897f97c0425f1c23dd623529f9f6e057014c5f1753a92cf17966f2c89f0', 'features': None, 'use_auth_token': None, 'base_path': 'data_scripts', 'add_sep': False}/data_xor/default/0.0.0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 269.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "model_wrapped = RobertaWrapper(device=\"cuda\")\n",
    "test_dataset_xor = datasets.load_dataset(\"data_scripts/data_xor.py\", add_sep=False)[\"train\"]\n",
    "# test_dataloader = DataLoader(test_dataset_xor, batch_size=3)\n",
    "\n",
    "# print(next(iter(test_dataloader)))\n",
    "# output = model_wrapped(next(iter(test_dataloader))[\"content\"])\n",
    "# print(len(output))\n",
    "# print(output[0].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states_many_examples(model, data, n=100, layer=-1, batch_size=1):\n",
    "    \"\"\"\n",
    "    Takes a bunch of sequences and runs them through RoBERTa to generate the mean-pooled hidden states.\n",
    "\n",
    "    This is unbatched and kept inefficient for simplicity\n",
    "\n",
    "    can be done in batches on a GPU to make it faster\n",
    "    \"\"\"\n",
    "    # setup\n",
    "    model.eval()\n",
    "    all_hidden_states, all_labels = [], []\n",
    "    # all_hidden_states: will have elements for each RoBERTa layer, each element represents the mean-pooled representations for the whole data at that layer\n",
    "\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # loop\n",
    "    # for idx in tqdm(range(n)):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        if ((i+1) * batch_size) > n:\n",
    "            break\n",
    "        text, true_label = batch[\"content\"], batch[\"label\"].to(model.device)\n",
    "        ic(text)\n",
    "        ic(true_label)\n",
    "\n",
    "\n",
    "        # get hidden states\n",
    "        with torch.no_grad():\n",
    "            outs = model(text)\n",
    "        # outs: [hidden states]\n",
    "        ic(outs[0].size())\n",
    "\n",
    "        # initialize if empty\n",
    "        if len(all_hidden_states) == 0:\n",
    "            for i in range(len(outs)):\n",
    "                all_hidden_states.append([])\n",
    "\n",
    "\n",
    "        # collect\n",
    "        for i, hidden_state in enumerate(outs):\n",
    "            all_hidden_states[i].append(hidden_state)\n",
    "\n",
    "        all_labels.append(true_label)\n",
    "\n",
    "    ic(len(all_hidden_states))\n",
    "    ic(len(all_hidden_states[0]))\n",
    "    ic(all_hidden_states[0][0].size())\n",
    "    ic(torch.cat(all_hidden_states[0], dim=0).size())\n",
    "\n",
    "    all_hidden_states = [torch.cat(all_hidden_states[i], dim=0) for i in range(len(all_hidden_states))]\n",
    "\n",
    "\n",
    "    return all_hidden_states, torch.cat(all_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "torch.Size([6, 768])\n"
     ]
    }
   ],
   "source": [
    "ic.disable()\n",
    "outs = get_hidden_states_many_examples(model_wrapped, test_dataset_xor, n=4, batch_size=2)\n",
    "print(len(outs[0]))\n",
    "print(outs[0][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_across_layers(experiment, train_input, train_labels, test_input, test_labels):\n",
    "    \"\"\"\n",
    "    Runs a probing experiment over representations from all layers of the model.\n",
    "    The whole thing works on cached embeddings\n",
    "\n",
    "    experiment: method (train: Tensor, test: Tensor, label_train: Tensor, label_test: Tensor) -> (fit_model, metrics). Each experiment will fit _some_ model on the data and return the model and the results\n",
    "    train_input: list of 13 elements, each of which is a tensor of size (num_datapoints, embedding_dim)\n",
    "    train_labels: tensor (num_datapoints, )\n",
    "    test_input: same format as train_input\n",
    "    test_labels: same format as train_labels\n",
    "    \"\"\"\n",
    "\n",
    "    list_of_results = []\n",
    "    list_of_probing_models = []\n",
    "\n",
    "    for i in range(len(train_input)):\n",
    "        train_current_layer = train_input[i]\n",
    "        test_current_layer = test_input[i]\n",
    "\n",
    "        model, metrics = experiment(train_current_layer, test_current_layer, train_labels, test_labels)\n",
    "\n",
    "        list_of_results.append(metrics)\n",
    "        list_of_probing_models.append(model)\n",
    "\n",
    "    return list_of_probing_models, list_of_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_experiment(train_input, test_input, train_labels, test_labels, probe_model):\n",
    "    \"\"\"\n",
    "    Gets an initialized probe model and fits it on data and runs some experiments\n",
    "    expected to be curried and sent as a callback to run_experiment_across_layers\n",
    "    \"\"\"\n",
    "\n",
    "    train_input_numpy = train_input.detach().cpu().numpy()\n",
    "    test_input_numpy = test_input.detach().cpu().numpy()\n",
    "    ic(train_labels.size())\n",
    "    train_labels_numpy = train_labels.detach().cpu().numpy()\n",
    "    test_labels_numpy = test_labels.detach().cpu().numpy()\n",
    "\n",
    "    probe_model.fit(train_input_numpy, train_labels_numpy)\n",
    "\n",
    "    accuracy = probe_model.score(test_input_numpy, test_labels_numpy)\n",
    "\n",
    "    return probe_model, {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "def linear_probe_experiment(train_input, test_input, train_labels, test_labels):\n",
    "    # initialize linear probe and run probe experiment\n",
    "    lr = LogisticRegression(class_weight=\"balanced\", verbose=1, max_iter=1000)\n",
    "    return probe_experiment(train_input, test_input, train_labels, test_labels, lr)\n",
    "\n",
    "\n",
    "def mlp_probe_experiment(train_input, test_input, train_labels, test_labels):\n",
    "    # initialize an mlp probe and run probe experiment\n",
    "    mlp = MLPClassifier(random_state=1, max_iter=1000, verbose=True)\n",
    "    return probe_experiment(train_input, test_input, train_labels, test_labels, mlp)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The XOR experiment\n",
    "\n",
    "We have negated and non-negated versions of the same propositions in LAMA\n",
    "\n",
    "- A: Einstein was born in Austria\n",
    "- A': Eisntein was not born in Austria\n",
    "\n",
    "We make the following combinations\n",
    "- AA\n",
    "- AA'\n",
    "- A'A\n",
    "- A'A'\n",
    "\n",
    "We classify contradictory statements together and non-contradictory statements together\n",
    "\n",
    "The point is to ask if a linear regression can seperate out this classification, the point is to look if the model is doing compositionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Found cached dataset data_xor (/home/mrcreator/research/main_thread/fresh_repo/{'cache_dir': None, 'config_name': None, 'data_dir': None, 'data_files': None, 'hash': '70230897f97c0425f1c23dd623529f9f6e057014c5f1753a92cf17966f2c89f0', 'features': None, 'use_auth_token': None, 'base_path': 'data_scripts', 'add_sep': False}/data_xor/default/0.0.0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 459.63it/s]\n",
      "Found cached dataset data_xor (/home/mrcreator/research/main_thread/fresh_repo/{'cache_dir': None, 'config_name': None, 'data_dir': None, 'data_files': None, 'hash': '70230897f97c0425f1c23dd623529f9f6e057014c5f1753a92cf17966f2c89f0', 'features': None, 'use_auth_token': None, 'base_path': 'data_scripts', 'add_sep': False}/data_xor/default/0.0.0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 484.93it/s]\n",
      "Found cached dataset data_xor (/home/mrcreator/research/main_thread/fresh_repo/{'cache_dir': None, 'config_name': None, 'data_dir': None, 'data_files': None, 'hash': '70230897f97c0425f1c23dd623529f9f6e057014c5f1753a92cf17966f2c89f0', 'features': None, 'use_auth_token': None, 'base_path': 'data_scripts', 'add_sep': False}/data_xor/default/0.0.0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 598.25it/s]\n"
     ]
    }
   ],
   "source": [
    "ic.disable()\n",
    "model_wrapped = RobertaWrapper(device=\"cuda\")\n",
    "train_dataset_xor = datasets.load_dataset(\"data_scripts/data_xor.py\", add_sep=False)[\"train\"]\n",
    "test_dataset_xor = datasets.load_dataset(\"data_scripts/data_xor.py\", add_sep=False)[\"test\"]\n",
    "dev_dataset_xor = datasets.load_dataset(\"data_scripts/data_xor.py\", add_sep=False)[\"validation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_labels = get_hidden_states_many_examples(model_wrapped, train_dataset_xor, n=2000, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, test_labels = get_hidden_states_many_examples(model_wrapped, test_dataset_xor, n=10000, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2100])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(len(test_labels))\n",
    "ic(test_labels.size())\n",
    "ic(train_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  2.23122D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  1.45242D+03    |proj g|=  2.07720D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769     69     84      1     0     0   2.383D-01   1.452D+03\n",
      "  F =   1452.4206590271517     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  8.87901D+00\n",
      "\n",
      "At iterate   50    f=  1.38178D+03    |proj g|=  2.85279D+00\n",
      "\n",
      "At iterate  100    f=  1.37762D+03    |proj g|=  4.13870D+01\n",
      "\n",
      "At iterate  150    f=  1.37663D+03    |proj g|=  2.97917D+00\n",
      "\n",
      "At iterate  200    f=  1.37642D+03    |proj g|=  1.96693D+00\n",
      "\n",
      "At iterate  250    f=  1.37636D+03    |proj g|=  3.88501D-01\n",
      "\n",
      "At iterate  300    f=  1.37631D+03    |proj g|=  1.21339D+00\n",
      "\n",
      "At iterate  350    f=  1.37602D+03    |proj g|=  3.79493D-01\n",
      "\n",
      "At iterate  400    f=  1.37581D+03    |proj g|=  2.35910D+00\n",
      "\n",
      "At iterate  450    f=  1.37570D+03    |proj g|=  2.09941D+00\n",
      "\n",
      "At iterate  500    f=  1.37567D+03    |proj g|=  2.08438D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    528    618      1     0     0   1.758D-01   1.376D+03\n",
      "  F =   1375.6650630575275     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  4.53100D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  1.38977D+03    |proj g|=  2.40347D+01\n",
      "\n",
      "At iterate  100    f=  1.38576D+03    |proj g|=  2.31115D+01\n",
      "\n",
      "At iterate  150    f=  1.38479D+03    |proj g|=  8.98988D+00\n",
      "\n",
      "At iterate  200    f=  1.38445D+03    |proj g|=  7.76181D+00\n",
      "\n",
      "At iterate  250    f=  1.38428D+03    |proj g|=  1.71028D-01\n",
      "\n",
      "At iterate  300    f=  1.38424D+03    |proj g|=  1.47105D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    312    375      1     0     0   2.287D-01   1.384D+03\n",
      "  F =   1384.2404216185255     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  5.81895D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  1.14196D+03    |proj g|=  2.90065D+01\n",
      "\n",
      "At iterate  100    f=  1.10708D+03    |proj g|=  1.29370D+02\n",
      "\n",
      "At iterate  150    f=  1.10533D+03    |proj g|=  2.81714D+00\n",
      "\n",
      "At iterate  200    f=  1.10505D+03    |proj g|=  2.23574D+00\n",
      "\n",
      "At iterate  250    f=  1.10499D+03    |proj g|=  5.29868D+00\n",
      "\n",
      "At iterate  300    f=  1.10497D+03    |proj g|=  2.03058D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    346    420      1     0     0   9.642D-01   1.105D+03\n",
      "  F =   1104.9661927982297     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  1.35238D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  7.37320D+02    |proj g|=  2.45211D+01\n",
      "\n",
      "At iterate  100    f=  7.33706D+02    |proj g|=  7.10853D+00\n",
      "\n",
      "At iterate  150    f=  7.33584D+02    |proj g|=  3.40295D-01\n",
      "\n",
      "At iterate  200    f=  7.33579D+02    |proj g|=  1.35860D-01\n",
      "\n",
      "At iterate  250    f=  7.33576D+02    |proj g|=  1.83854D+00\n",
      "\n",
      "At iterate  300    f=  7.33568D+02    |proj g|=  1.38174D+00\n",
      "\n",
      "At iterate  350    f=  7.33541D+02    |proj g|=  1.86292D+00\n",
      "\n",
      "At iterate  400    f=  7.33446D+02    |proj g|=  2.54085D+00\n",
      "\n",
      "At iterate  450    f=  7.33260D+02    |proj g|=  4.40727D+00\n",
      "\n",
      "At iterate  500    f=  7.33211D+02    |proj g|=  4.36209D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    540    648      1     0     0   2.995D-01   7.332D+02\n",
      "  F =   733.20045610456089     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  3.07460D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  4.93298D+02    |proj g|=  1.19786D+02\n",
      "\n",
      "At iterate  100    f=  4.63185D+02    |proj g|=  1.36461D+01\n",
      "\n",
      "At iterate  150    f=  4.59399D+02    |proj g|=  1.99574D+01\n",
      "\n",
      "At iterate  200    f=  4.58764D+02    |proj g|=  7.05298D+00\n",
      "\n",
      "At iterate  250    f=  4.58618D+02    |proj g|=  9.24198D-01\n",
      "\n",
      "At iterate  300    f=  4.58577D+02    |proj g|=  3.90435D+00\n",
      "\n",
      "At iterate  350    f=  4.58557D+02    |proj g|=  1.35971D-01\n",
      "\n",
      "At iterate  400    f=  4.58474D+02    |proj g|=  1.10376D+00\n",
      "\n",
      "At iterate  450    f=  4.57796D+02    |proj g|=  2.22877D+00\n",
      "\n",
      "At iterate  500    f=  4.57104D+02    |proj g|=  2.65336D+00\n",
      "\n",
      "At iterate  550    f=  4.56717D+02    |proj g|=  1.52169D+00\n",
      "\n",
      "At iterate  600    f=  4.56501D+02    |proj g|=  1.17525D+01\n",
      "\n",
      "At iterate  650    f=  4.56456D+02    |proj g|=  1.75084D+00\n",
      "\n",
      "At iterate  700    f=  4.56451D+02    |proj g|=  1.09078D-01\n",
      "\n",
      "At iterate  750    f=  4.56450D+02    |proj g|=  5.55830D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    754    896      1     0     0   9.773D-03   4.564D+02\n",
      "  F =   456.44984712601627     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  7.86480D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  3.35829D+02    |proj g|=  3.35864D+00\n",
      "\n",
      "At iterate  100    f=  3.35564D+02    |proj g|=  1.03660D-01\n",
      "\n",
      "At iterate  150    f=  3.35550D+02    |proj g|=  3.66455D-01\n",
      "\n",
      "At iterate  200    f=  3.35545D+02    |proj g|=  7.06072D-01\n",
      "\n",
      "At iterate  250    f=  3.35532D+02    |proj g|=  9.43234D-01\n",
      "\n",
      "At iterate  300    f=  3.35451D+02    |proj g|=  6.48501D-01\n",
      "\n",
      "At iterate  350    f=  3.35215D+02    |proj g|=  2.57483D-01\n",
      "\n",
      "At iterate  400    f=  3.35198D+02    |proj g|=  1.21992D+00\n",
      "\n",
      "At iterate  450    f=  3.35197D+02    |proj g|=  2.16696D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    458    544      1     0     0   2.292D-02   3.352D+02\n",
      "  F =   335.19669903243096     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  8.59161D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.76272D+02    |proj g|=  9.31532D+00\n",
      "\n",
      "At iterate  100    f=  2.75101D+02    |proj g|=  2.34346D+00\n",
      "\n",
      "At iterate  150    f=  2.75062D+02    |proj g|=  2.08108D+00\n",
      "\n",
      "At iterate  200    f=  2.75056D+02    |proj g|=  8.71511D-02\n",
      "\n",
      "At iterate  250    f=  2.75051D+02    |proj g|=  1.05374D+00\n",
      "\n",
      "At iterate  300    f=  2.75006D+02    |proj g|=  1.99765D+00\n",
      "\n",
      "At iterate  350    f=  2.74825D+02    |proj g|=  6.53202D+00\n",
      "\n",
      "At iterate  400    f=  2.74743D+02    |proj g|=  4.97777D-01\n",
      "\n",
      "At iterate  450    f=  2.74737D+02    |proj g|=  3.62901D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    492    584      1     0     0   7.156D-02   2.747D+02\n",
      "  F =   274.73632728175176     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  1.01707D+02\n",
      "\n",
      "At iterate   50    f=  2.20617D+02    |proj g|=  4.55568D+00\n",
      "\n",
      "At iterate  100    f=  2.19937D+02    |proj g|=  1.09681D-01\n",
      "\n",
      "At iterate  150    f=  2.19929D+02    |proj g|=  1.52697D-01\n",
      "\n",
      "At iterate  200    f=  2.19928D+02    |proj g|=  1.84781D-01\n",
      "\n",
      "At iterate  250    f=  2.19913D+02    |proj g|=  1.37203D+00\n",
      "\n",
      "At iterate  300    f=  2.19851D+02    |proj g|=  6.31220D-01\n",
      "\n",
      "At iterate  350    f=  2.19835D+02    |proj g|=  6.40748D-01\n",
      "\n",
      "At iterate  400    f=  2.19828D+02    |proj g|=  3.99210D-01\n",
      "\n",
      "At iterate  450    f=  2.19826D+02    |proj g|=  9.07427D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    480    576      1     0     0   3.451D-02   2.198D+02\n",
      "  F =   219.82560658103998     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  6.81423D+01\n",
      "\n",
      "At iterate   50    f=  2.16511D+02    |proj g|=  9.90411D+00\n",
      "\n",
      "At iterate  100    f=  2.11491D+02    |proj g|=  2.82308D+00\n",
      "\n",
      "At iterate  150    f=  2.11447D+02    |proj g|=  2.72227D-01\n",
      "\n",
      "At iterate  200    f=  2.11446D+02    |proj g|=  7.53485D-02\n",
      "\n",
      "At iterate  250    f=  2.11445D+02    |proj g|=  2.01169D-02\n",
      "\n",
      "At iterate  300    f=  2.11443D+02    |proj g|=  9.63600D-02\n",
      "\n",
      "At iterate  350    f=  2.11420D+02    |proj g|=  1.90204D+00\n",
      "\n",
      "At iterate  400    f=  2.11398D+02    |proj g|=  5.41451D-02\n",
      "\n",
      "At iterate  450    f=  2.11397D+02    |proj g|=  2.77292D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    472    577      1     0     0   3.842D-02   2.114D+02\n",
      "  F =   211.39692996332110     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  7.93690D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.37588D+02    |proj g|=  1.18714D+01\n",
      "\n",
      "At iterate  100    f=  2.36568D+02    |proj g|=  5.10607D+00\n",
      "\n",
      "At iterate  150    f=  2.36518D+02    |proj g|=  8.49448D-02\n",
      "\n",
      "At iterate  200    f=  2.36510D+02    |proj g|=  6.83787D-02\n",
      "\n",
      "At iterate  250    f=  2.36508D+02    |proj g|=  4.76246D-01\n",
      "\n",
      "At iterate  300    f=  2.36506D+02    |proj g|=  3.38607D-01\n",
      "\n",
      "At iterate  350    f=  2.36493D+02    |proj g|=  2.58453D+00\n",
      "\n",
      "At iterate  400    f=  2.36439D+02    |proj g|=  1.52603D+00\n",
      "\n",
      "At iterate  450    f=  2.36425D+02    |proj g|=  3.58681D-01\n",
      "\n",
      "At iterate  500    f=  2.36424D+02    |proj g|=  9.58418D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    502    595      1     0     0   1.574D-02   2.364D+02\n",
      "  F =   236.42362102933171     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  5.74914D+01\n",
      "\n",
      "At iterate   50    f=  2.51209D+02    |proj g|=  3.24970D+01\n",
      "\n",
      "At iterate  100    f=  2.49429D+02    |proj g|=  3.27517D-01\n",
      "\n",
      "At iterate  150    f=  2.49352D+02    |proj g|=  1.34209D+00\n",
      "\n",
      "At iterate  200    f=  2.49345D+02    |proj g|=  2.85390D-01\n",
      "\n",
      "At iterate  250    f=  2.49343D+02    |proj g|=  1.95163D-01\n",
      "\n",
      "At iterate  300    f=  2.49341D+02    |proj g|=  3.84187D-02\n",
      "\n",
      "At iterate  350    f=  2.49329D+02    |proj g|=  3.16519D-01\n",
      "\n",
      "At iterate  400    f=  2.49304D+02    |proj g|=  1.31859D+00\n",
      "\n",
      "At iterate  450    f=  2.49262D+02    |proj g|=  8.13346D-02\n",
      "\n",
      "At iterate  500    f=  2.49258D+02    |proj g|=  1.67881D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    509    604      1     0     0   1.051D-01   2.493D+02\n",
      "  F =   249.25815544498437     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45561D+03    |proj g|=  3.07314D+01\n",
      "\n",
      "At iterate   50    f=  4.80316D+02    |proj g|=  2.11832D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate  100    f=  4.78283D+02    |proj g|=  2.79193D+00\n",
      "\n",
      "At iterate  150    f=  4.78264D+02    |proj g|=  8.83223D-02\n",
      "\n",
      "At iterate  200    f=  4.78207D+02    |proj g|=  1.13388D+00\n",
      "\n",
      "At iterate  250    f=  4.78157D+02    |proj g|=  7.68531D-01\n",
      "\n",
      "At iterate  300    f=  4.78153D+02    |proj g|=  5.39956D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    320    381      1     0     0   7.467D-02   4.782D+02\n",
      "  F =   478.15323597714280     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1)],\n",
       " [{'accuracy': 0.5210891089108911},\n",
       "  {'accuracy': 0.5825742574257425},\n",
       "  {'accuracy': 0.585049504950495},\n",
       "  {'accuracy': 0.737029702970297},\n",
       "  {'accuracy': 0.8600990099009901},\n",
       "  {'accuracy': 0.9167326732673268},\n",
       "  {'accuracy': 0.9514851485148514},\n",
       "  {'accuracy': 0.9635643564356435},\n",
       "  {'accuracy': 0.9776237623762376},\n",
       "  {'accuracy': 0.9774257425742574},\n",
       "  {'accuracy': 0.9749504950495049},\n",
       "  {'accuracy': 0.9749504950495049},\n",
       "  {'accuracy': 0.9671287128712871}])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment_across_layers(linear_probe_experiment, train, train_labels, test, test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negation Detection\n",
    "\n",
    "Very dumb experiment, checking for negation in the statement (from mean-pooled reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset data_detect_neg (/home/mrcreator/research/main_thread/fresh_repo/{'cache_dir': None, 'config_name': None, 'data_dir': None, 'data_files': None, 'hash': '1b53f52a30ee637c38ac67e920770d58d6c1da4f3bed41fbe8442d79b6881e56', 'features': None, 'use_auth_token': None, 'base_path': 'data_scripts', 'add_sep': False}/data_detect_neg/default/0.0.0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 671.12it/s]\n",
      "Found cached dataset data_detect_neg (/home/mrcreator/research/main_thread/fresh_repo/{'cache_dir': None, 'config_name': None, 'data_dir': None, 'data_files': None, 'hash': '1b53f52a30ee637c38ac67e920770d58d6c1da4f3bed41fbe8442d79b6881e56', 'features': None, 'use_auth_token': None, 'base_path': 'data_scripts', 'add_sep': False}/data_detect_neg/default/0.0.0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 509.80it/s]\n",
      "Found cached dataset data_detect_neg (/home/mrcreator/research/main_thread/fresh_repo/{'cache_dir': None, 'config_name': None, 'data_dir': None, 'data_files': None, 'hash': '1b53f52a30ee637c38ac67e920770d58d6c1da4f3bed41fbe8442d79b6881e56', 'features': None, 'use_auth_token': None, 'base_path': 'data_scripts', 'add_sep': False}/data_detect_neg/default/0.0.0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 425.76it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset_neg_detect = datasets.load_dataset(\"data_scripts/data_detect_neg.py\", add_sep=False)[\"train\"]\n",
    "test_dataset_neg_detect = datasets.load_dataset(\"data_scripts/data_detect_neg.py\", add_sep=False)[\"test\"]\n",
    "dev_dataset_neg_detect = datasets.load_dataset(\"data_scripts/data_detect_neg.py\", add_sep=False)[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_detect_neg, train_labels_det_neg = get_hidden_states_many_examples(model_wrapped, train_dataset_neg_detect, n=2000, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_detect_neg, test_labels_det_neg = get_hidden_states_many_examples(model_wrapped, test_dataset_neg_detect, n=10000, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  3.32225D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.04545D+02    |proj g|=  7.64498D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769     77     90      1     0     0   9.888D-04   2.045D+02\n",
      "  F =   204.53285633775937     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  6.85403D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  1.24328D+02    |proj g|=  2.31646D+00\n",
      "\n",
      "At iterate  100    f=  1.24240D+02    |proj g|=  4.26313D-02\n",
      "\n",
      "At iterate  150    f=  1.24191D+02    |proj g|=  1.07950D+00\n",
      "\n",
      "At iterate  200    f=  1.24187D+02    |proj g|=  1.55634D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    221    257      1     0     0   8.335D-04   1.242D+02\n",
      "  F =   124.18733996052116     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  8.76241D+01\n",
      "\n",
      "At iterate   50    f=  1.18364D+02    |proj g|=  1.78367D+00\n",
      "\n",
      "At iterate  100    f=  1.18296D+02    |proj g|=  2.40666D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    135    152      1     0     0   1.686D-02   1.183D+02\n",
      "  F =   118.29520162589269     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  9.52775D+01\n",
      "\n",
      "At iterate   50    f=  1.16833D+02    |proj g|=  1.88923D+00\n",
      "\n",
      "At iterate  100    f=  1.16655D+02    |proj g|=  1.36041D+00\n",
      "\n",
      "At iterate  150    f=  1.16652D+02    |proj g|=  2.10000D-01\n",
      "\n",
      "At iterate  200    f=  1.16599D+02    |proj g|=  2.52958D+00\n",
      "\n",
      "At iterate  250    f=  1.16533D+02    |proj g|=  2.55485D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    288    338      1     0     0   1.466D-03   1.165D+02\n",
      "  F =   116.53231400271187     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  9.66319D+01\n",
      "\n",
      "At iterate   50    f=  1.12514D+02    |proj g|=  4.09364D+00\n",
      "\n",
      "At iterate  100    f=  1.12424D+02    |proj g|=  3.34658D-02\n",
      "\n",
      "At iterate  150    f=  1.12392D+02    |proj g|=  2.10947D+00\n",
      "\n",
      "At iterate  200    f=  1.12299D+02    |proj g|=  6.76007D-02\n",
      "\n",
      "At iterate  250    f=  1.12291D+02    |proj g|=  3.16846D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    261    302      1     0     0   2.026D-02   1.123D+02\n",
      "  F =   112.29124508297348     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  1.05673D+02\n",
      "\n",
      "At iterate   50    f=  9.97154D+01    |proj g|=  1.16181D+00\n",
      "\n",
      "At iterate  100    f=  9.94567D+01    |proj g|=  3.38586D-01\n",
      "\n",
      "At iterate  150    f=  9.94530D+01    |proj g|=  7.67354D-02\n",
      "\n",
      "At iterate  200    f=  9.93549D+01    |proj g|=  1.76517D+00\n",
      "\n",
      "At iterate  250    f=  9.92998D+01    |proj g|=  6.80629D-01\n",
      "\n",
      "At iterate  300    f=  9.92980D+01    |proj g|=  2.56711D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    300    355      1     0     0   2.567D-02   9.930D+01\n",
      "  F =   99.298039687483652     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  1.15866D+02\n",
      "\n",
      "At iterate   50    f=  9.87568D+01    |proj g|=  1.97864D-01\n",
      "\n",
      "At iterate  100    f=  9.87074D+01    |proj g|=  1.22188D-01\n",
      "\n",
      "At iterate  150    f=  9.86906D+01    |proj g|=  1.64428D+00\n",
      "\n",
      "At iterate  200    f=  9.85642D+01    |proj g|=  8.29998D-02\n",
      "\n",
      "At iterate  250    f=  9.85567D+01    |proj g|=  1.07981D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    266    304      1     0     0   2.525D-03   9.856D+01\n",
      "  F =   98.556615830188392     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  1.10859D+02\n",
      "\n",
      "At iterate   50    f=  9.56001D+01    |proj g|=  4.32750D+00\n",
      "\n",
      "At iterate  100    f=  9.53668D+01    |proj g|=  3.06772D-01\n",
      "\n",
      "At iterate  150    f=  9.53629D+01    |proj g|=  6.56175D-01\n",
      "\n",
      "At iterate  200    f=  9.53334D+01    |proj g|=  4.24689D+00\n",
      "\n",
      "At iterate  250    f=  9.51900D+01    |proj g|=  1.80423D+00\n",
      "\n",
      "At iterate  300    f=  9.51655D+01    |proj g|=  2.39485D-01\n",
      "\n",
      "At iterate  350    f=  9.51651D+01    |proj g|=  1.57215D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    352    420      1     0     0   3.563D-02   9.517D+01\n",
      "  F =   95.165074383945154     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  1.18782D+02\n",
      "\n",
      "At iterate   50    f=  9.46269D+01    |proj g|=  4.35112D+00\n",
      "\n",
      "At iterate  100    f=  9.43411D+01    |proj g|=  8.65839D-01\n",
      "\n",
      "At iterate  150    f=  9.43328D+01    |proj g|=  3.43572D-01\n",
      "\n",
      "At iterate  200    f=  9.43028D+01    |proj g|=  2.45027D+00\n",
      "\n",
      "At iterate  250    f=  9.41723D+01    |proj g|=  4.84260D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    291    343      1     0     0   2.990D-02   9.416D+01\n",
      "  F =   94.162954357943121     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  1.24954D+02\n",
      "\n",
      "At iterate   50    f=  9.40611D+01    |proj g|=  2.12306D+00\n",
      "\n",
      "At iterate  100    f=  9.38564D+01    |proj g|=  1.34114D-01\n",
      "\n",
      "At iterate  150    f=  9.38533D+01    |proj g|=  1.49877D-01\n",
      "\n",
      "At iterate  200    f=  9.38198D+01    |proj g|=  4.14386D-01\n",
      "\n",
      "At iterate  250    f=  9.37334D+01    |proj g|=  1.00106D+00\n",
      "\n",
      "At iterate  300    f=  9.37281D+01    |proj g|=  2.18188D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    308    358      1     0     0   1.462D-02   9.373D+01\n",
      "  F =   93.728067621968592     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  1.23173D+02\n",
      "\n",
      "At iterate   50    f=  9.79266D+01    |proj g|=  8.36408D+00\n",
      "\n",
      "At iterate  100    f=  9.75858D+01    |proj g|=  1.26014D-01\n",
      "\n",
      "At iterate  150    f=  9.75823D+01    |proj g|=  1.26635D-01\n",
      "\n",
      "At iterate  200    f=  9.75009D+01    |proj g|=  7.56717D-01\n",
      "\n",
      "At iterate  250    f=  9.74839D+01    |proj g|=  1.18486D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    265    315      1     0     0   3.769D-02   9.748D+01\n",
      "  F =   97.483860475440594     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  1.33309D+02\n",
      "\n",
      "At iterate   50    f=  1.11224D+02    |proj g|=  9.15769D-01\n",
      "\n",
      "At iterate  100    f=  1.10809D+02    |proj g|=  1.17546D+00\n",
      "\n",
      "At iterate  150    f=  1.10801D+02    |proj g|=  4.81832D-02\n",
      "\n",
      "At iterate  200    f=  1.10794D+02    |proj g|=  3.47335D-01\n",
      "\n",
      "At iterate  250    f=  1.10709D+02    |proj g|=  5.41799D-01\n",
      "\n",
      "At iterate  300    f=  1.10635D+02    |proj g|=  1.88228D-01\n",
      "\n",
      "At iterate  350    f=  1.10633D+02    |proj g|=  7.05715D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    366    428      1     0     0   1.870D-02   1.106D+02\n",
      "  F =   110.63293522128515     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          769     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38629D+03    |proj g|=  6.48358D+01\n",
      "\n",
      "At iterate   50    f=  2.27067D+02    |proj g|=  2.24334D+00\n",
      "\n",
      "At iterate  100    f=  2.26869D+02    |proj g|=  1.10526D+00\n",
      "\n",
      "At iterate  150    f=  2.26733D+02    |proj g|=  4.45661D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  769    170    203      1     0     0   1.872D-02   2.267D+02\n",
      "  F =   226.73187817552341     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1),\n",
       "  LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1)],\n",
       " [{'accuracy': 0.9832},\n",
       "  {'accuracy': 0.9828},\n",
       "  {'accuracy': 0.9832},\n",
       "  {'accuracy': 0.9831},\n",
       "  {'accuracy': 0.9831},\n",
       "  {'accuracy': 0.983},\n",
       "  {'accuracy': 0.9832},\n",
       "  {'accuracy': 0.9833},\n",
       "  {'accuracy': 0.9833},\n",
       "  {'accuracy': 0.9833},\n",
       "  {'accuracy': 0.9834},\n",
       "  {'accuracy': 0.9833},\n",
       "  {'accuracy': 0.983}])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment_across_layers(linear_probe_experiment, train_detect_neg, train_labels_det_neg, test_detect_neg, test_labels_det_neg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
